{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oligo Design\n",
    "\n",
    "For Nucleaseq, we want to design sequences with the following basic structure:\n",
    "\n",
    "| Left primer | Left BC | Left buffer | Target$_n$ | Right buffer | Right fill | Right BC | Right primer |\n",
    "| - | - | - | - | - | - | - | - |\n",
    "\n",
    "Where Target$_n$ is from the set of all desired modified target sequences. \n",
    "\n",
    "The set of Target$_n$'s is specific to each experiment, but there are some relatively standard sets. For example, most experiments will wish to include all single- and double-mismatch sequences. While on the other hand, the PAM structure for each CRISPR variant is different and may require custom sequence generation. And other nucleases may have entirely different needs.\n",
    "\n",
    "To handle this, we have a number of functions for standard modifications in design.py, which can be called below, while at the same time we have a space explicitly reserved for custom sequence generation: \"Custom sequence functions\". After the set of target-generation functions is complete, they need added to the \"Construct Sequences\" section below, in the manner shown by the included examples. Go through this section carefully to verify the set of included sequences is correct.\n",
    "\n",
    "The \"Run parameters\" section needs updated according to the experimental requirements, as well. One parameter which needs specified is a list all canonical cut positions along the target sequence. This needs to be a python integer with \".5\" after it to indicate the cut position. For instance, 18.5 cuts between python indices 18 and 19. The lower portion of this notebook needs this information to find appropriate primer sequences.\n",
    "\n",
    "Finally, the user is expected to adjust the primers as necessary to fit their experimental conditions. See the \"Replace Primers\" section for details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequence Motifs\n",
    "\n",
    "### For this example, we want the following sequences and modifications:\n",
    "\n",
    "* Target D-Nme2\n",
    "* single mismatches\n",
    "* double mismatches\n",
    "* single insertions\n",
    "* double insertions\n",
    "* single deletions \n",
    "* double deletions\n",
    "* scanning mismatch regions (using the complement) for 3 bp to 24 bp length regions\n",
    "* Perfect target with different buffer regions\n",
    "* Perfect target with various barcodes\n",
    "* Random negative control seqs\n",
    "* Various 4N PAM subsets\n",
    "* single mm and single ins seqs\n",
    "* single mm and single del seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "notebook_start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import yaml\n",
    "import itertools\n",
    "import random\n",
    "import math\n",
    "import logging\n",
    "import scipy.misc\n",
    "import editdistance\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from collections import defaultdict, Counter\n",
    "from Bio.Seq import Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nucleaseq.NucleaSeqOligo import NucleaSeqOligo\n",
    "from nucleaseq.equalmarginalseqs import generate_clean_random_eqmarg_seqs\n",
    "from nucleaseq import design, seqtools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "master_seed = 43\n",
    "random.seed(master_seed)\n",
    "rand_seeds = [random.randint(0, 100) for i in range(10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_desired_seqs = 12472\n",
    "n_err_detect_seqs = 150  # Number of random sequences for negative control\n",
    "min_perfect_target_copies = 50\n",
    "\n",
    "targets_fpath = '/shared/targets.yml'\n",
    "target_name = 'D'\n",
    "\n",
    "barcodes_fpath = '/mnt/marble/hdd2/hawkjo/barcode_and_nucleaseq/src/freebarcodes/barcodes/barcodes17-2.txt'\n",
    "barcodes = [line.strip() for line in open(barcodes_fpath)]\n",
    "\n",
    "min_primer_len = 21  # First length to try. Will go smaller if possible. Adjust this if notebook too slow.\n",
    "max_primer_len = 30\n",
    "\n",
    "bad_substrs = ['CC', 'GG', 'AAA', 'TTT'] # Forbidden subseqs in buffers or primers (here Cas9 or Cas12a PAMs)\n",
    "\n",
    "nprocs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consider cut sites within 5 bp of pamtarg positions: [-3, -1, 3]\n"
     ]
    }
   ],
   "source": [
    "h_cannonical_cut_sites = [20.5, 22.5, 26.5]  # Include all cut sites on all strands, absolute coordinates\n",
    "fudge_factor = 5             # How far from a cannonical cut site are possible cuts\n",
    "min_buffer_len = 5           # Min length of target-flanking buffers\n",
    "\n",
    "pamtarg_coord_one_pos = 24   # Position in the target sequence just to the right of the PAM-target boundary\n",
    "abs_cannonical_cut_sites = [int(math.ceil(ccs)) for ccs in h_cannonical_cut_sites]\n",
    "cannonical_cut_sites = [ccs - pamtarg_coord_one_pos for ccs in abs_cannonical_cut_sites] # convert to pamtarg coords\n",
    "\n",
    "print 'Consider cut sites within {} bp of pamtarg positions: {}'.format(fudge_factor, cannonical_cut_sites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "targets = yaml.load(open(targets_fpath))\n",
    "target = targets[target_name]\n",
    "target_seeds = [target[:14], target[-13:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target D (27 bp): TTTAGTGATAAGTGGAATGCCATGTGG\n",
      "Target seeds:\n",
      "    (14 bp): TTTAGTGATAAGTG\n",
      "    (13 bp): GAATGCCATGTGG\n",
      "Cannonical cut sites:\n",
      "    TTTAGTGATAAGTGGAATGCC x ATGTGG\n",
      "    TTTAGTGATAAGTGGAATGCCAT x GTGG\n",
      "    TTTAGTGATAAGTGGAATGCCATGTGG x \n"
     ]
    }
   ],
   "source": [
    "print 'Target {} ({} bp): {}'.format(target_name, len(target), target)\n",
    "print 'Target seeds:'\n",
    "for target_seed in target_seeds:\n",
    "    print '    ({} bp): {}'.format(len(target_seed), target_seed)\n",
    "print 'Cannonical cut sites:'\n",
    "for ccs in h_cannonical_cut_sites:\n",
    "    ccs = int(math.ceil(ccs))\n",
    "    print '    {} x {}'.format(target[:ccs], target[ccs:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Static Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bases = 'ACGT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temp left/right buffers: ATCGA ATGCA\n",
      "Temp primer 1: 18 bp, 50.0% GC  AGATCGCAGCTCGTCAAT\n",
      "Temp primer 2 (rev_comp): 18 bp, 50.0% GC  CGTCATAATGAACGCGCT\n"
     ]
    }
   ],
   "source": [
    "random.seed(rand_seeds[7])\n",
    "cr1 = design.shuffled_equalish_bases(18, bad_substrs)\n",
    "cr2 = design.shuffled_equalish_bases(18, bad_substrs)\n",
    "\n",
    "buffer1 = design.get_buffer(5, 'left', target, bad_substrs)\n",
    "buffer2 = design.get_buffer(5, 'right', target, bad_substrs)\n",
    "\n",
    "print 'Temp left/right buffers:', buffer1, buffer2\n",
    "print 'Temp primer 1: {} bp, {:.1f}% GC  {}'.format(len(cr1), \n",
    "                                               100*(cr1.count('C') + cr1.count('G'))/float(len(cr1)),\n",
    "                                               cr1)\n",
    "print 'Temp primer 2 (rev_comp): {} bp, {:.1f}% GC  {}'.format(len(cr2), \n",
    "                                               100*(cr2.count('C') + cr2.count('G'))/float(len(cr2)),\n",
    "                                               cr2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generation of Sequences for Pilot Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from freebarcodes.editmeasures import simple_hamming_distance\n",
    "import freebarcodes.seqtools as fbseqtools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom sequence functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "interesting_pams = [\n",
    "    'NNCTTN',\n",
    "    'NNCCTN',\n",
    "    'NNTCTN',\n",
    "    'NNCGCN',\n",
    "    'NNTTTN',\n",
    "    'NNATTN',\n",
    "    'NNGTTN',\n",
    "    'NNGCTN',\n",
    "    'NNACTN',\n",
    "    'NNTTCN',\n",
    "    'NNCATN',\n",
    "    'NNTCCN',\n",
    "    'NNCCCN',\n",
    "]\n",
    "\n",
    "def get_interesting_pam_seqs():\n",
    "    assert target.startswith('TTTA'), target\n",
    "    template_seq = target[4:]\n",
    "    output = set()\n",
    "    for pam in interesting_pams:\n",
    "        pam_kernel = pam[2:5]\n",
    "        for b1, b2, b3 in itertools.product(bases, repeat=3):\n",
    "            output.add(b1 + b2 + pam_kernel + b3 + template_seq)\n",
    "    return output\n",
    "\n",
    "def next_different_base(samp):\n",
    "    samp_bases = set(samp)\n",
    "    assert len(samp_bases) < 4, samp\n",
    "    for b in bases:\n",
    "        if b not in samp_bases:\n",
    "            return b\n",
    "        \n",
    "def get_one_mm_seq_per_pos(seq):\n",
    "    output = set()\n",
    "    for i in range(len(seq)):\n",
    "        # Choose mismatch to be different from ref base and neighboring bases\n",
    "        neighborhood = seq[max(i-1, 0):i+2]\n",
    "        assert len(neighborhood) == 3 or i == 0 or i == len(seq) - 1, (i, neighborhood)\n",
    "        output.add(seq[:i] + next_different_base(neighborhood) + seq[i+1:])\n",
    "    return output\n",
    "        \n",
    "def get_one_ins_seq_per_pos(seq):\n",
    "    output = set()\n",
    "    for i in range(len(seq)):\n",
    "        # Choose insertion to be different from either neighboring base\n",
    "        neighborhood = seq[max(i-1, 0):i+1]\n",
    "        assert len(neighborhood) == 2 or i == 0, (i, neighborhood)\n",
    "        output.add(seq[:i] + next_different_base(neighborhood) + seq[i:])\n",
    "    return output\n",
    "                \n",
    "def get_single_mm_single_del_seqs():\n",
    "    output = set()\n",
    "    for del_seq in fbseqtools.get_deletion_seqs(target, 1):\n",
    "        output.update(get_one_mm_seq_per_pos(del_seq))\n",
    "    return output\n",
    "\n",
    "def get_single_mm_single_ins_seqs():\n",
    "    output = set()\n",
    "    for mm_seq in get_one_mm_seq_per_pos(target):\n",
    "        output.update(get_one_ins_seq_per_pos(mm_seq))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "log = logging.getLogger()\n",
    "log.addHandler(logging.StreamHandler())\n",
    "log.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Max / min accepted / min barcode distances to target seed: 9 / 6 / 2\n",
      "\n",
      "Interesting PAM seqs: 832\n",
      "Single mm, Single del seqs: 507\n",
      "Single mm, Single ins seqs: 720\n",
      "Single mismatch seqs: 81\n",
      "Single insertion seqs: 82\n",
      "Single deletion seqs: 20\n",
      "Complement stretch seqs: 351\n",
      "Alternative targets: 25\n",
      "Double mismatch seqs: 3159\n",
      "Double deletion seqs: 191\n",
      "Double insertion seqs: 3315\n",
      "Alternative buffer with perfect target seqs: 15\n",
      "Perfect target with different barcode seqs: 50\n",
      "Before search min error detection seq dist to target seed quartiles: 2 / 5 / 5 / 6 / 6\n",
      "After search min error detection seq dist to target seed quartiles: 4 / 5 / 5 / 6 / 6\n",
      "Error detection seqs: 150\n",
      "Remaining seqs to be filled: 3038\n",
      "Total copies/sequences of single error seqs: 17/3111\n",
      "Added perfect seqs: 110\n",
      "Total perfect seqs: 175\n",
      "Total sequences generated: 12472\n"
     ]
    }
   ],
   "source": [
    "# This cell is the heart of the sequence construction. It is a single cell to \n",
    "# guarantee all parts are always performed together, so make reproducible output.\n",
    "\n",
    "#----------------------------------------------------------------------------------\n",
    "# Setup the barcode pairs\n",
    "#----------------------------------------------------------------------------------\n",
    "\n",
    "def min_dist_to_target_seed(s):\n",
    "    min_dists = []\n",
    "    for target_seed in target_seeds:\n",
    "        if len(s) > len(target_seed):\n",
    "            slong, sshort = s, target_seed\n",
    "        else:\n",
    "            slong, sshort = target_seed, s\n",
    "        slong_rc = seqtools.dna_rev_comp(slong)\n",
    "        min_dists.append(min(editdistance.eval(sshort, sl[i:i+len(sshort)]) \n",
    "                             for i in range(len(slong) - len(sshort) + 1)\n",
    "                             for sl in [slong, slong_rc]))\n",
    "    return min(min_dists)\n",
    "\n",
    "barcodes.sort(key=min_dist_to_target_seed, reverse=True) # Prefer barcodes less similar to target\n",
    "err_barcodes = barcodes[:n_err_detect_seqs]\n",
    "norm_barcodes = barcodes[n_err_detect_seqs:total_desired_seqs]\n",
    "log.info('Max / min accepted / min barcode distances to target seed: {} / {} / {}\\n'.format(\n",
    "    min_dist_to_target_seed(err_barcodes[0]),\n",
    "    min_dist_to_target_seed(norm_barcodes[-1]),\n",
    "    min_dist_to_target_seed(barcodes[-1])\n",
    "))\n",
    "\n",
    "random.seed(rand_seeds[2])\n",
    "random.shuffle(norm_barcodes)\n",
    "random.shuffle(err_barcodes)\n",
    "\n",
    "barcode_pairs, err_barcode_pairs = [], []\n",
    "for i in xrange(len(norm_barcodes)):\n",
    "    bc1 = norm_barcodes[i]\n",
    "    i2 = (i+1) % len(norm_barcodes)\n",
    "    bc2_rc = str(Seq(norm_barcodes[i2]).reverse_complement())\n",
    "    barcode_pairs.append((bc1, bc2_rc))\n",
    "for i in xrange(len(err_barcodes)):\n",
    "    bc1 = err_barcodes[i]\n",
    "    i2 = (i+1) % len(err_barcodes)\n",
    "    bc2_rc = str(Seq(err_barcodes[i2]).reverse_complement())\n",
    "    err_barcode_pairs.append((bc1, bc2_rc))\n",
    "\n",
    "    \n",
    "#----------------------------------------------------------------------------------\n",
    "# Custom sequences\n",
    "#----------------------------------------------------------------------------------\n",
    "\n",
    "sequence_set = set()\n",
    "\n",
    "# Interesting PAMs\n",
    "interesting_pam_seqs = get_interesting_pam_seqs()\n",
    "sequence_set.update(interesting_pam_seqs)\n",
    "log.info('Interesting PAM seqs: {}'.format(len(interesting_pam_seqs)))\n",
    "\n",
    "# Single mm and single del\n",
    "single_mm_single_del_sequences = get_single_mm_single_del_seqs()\n",
    "log.info('Single mm, Single del seqs: %d' % len(single_mm_single_del_sequences))\n",
    "sequence_set.update(single_mm_single_del_sequences)\n",
    "\n",
    "# Single mm and single ins\n",
    "single_mm_single_ins_sequences = get_single_mm_single_ins_seqs()\n",
    "log.info('Single mm, Single ins seqs: %d' % len(single_mm_single_ins_sequences))\n",
    "sequence_set.update(single_mm_single_ins_sequences)\n",
    "\n",
    "\n",
    "#----------------------------------------------------------------------------------\n",
    "# Standard sequences\n",
    "#----------------------------------------------------------------------------------\n",
    "\n",
    "# All possible single mismatches and indels\n",
    "single_mismatches = fbseqtools.get_mismatch_seqs(target, 1)\n",
    "sequence_set.update(single_mismatches)\n",
    "log.info('Single mismatch seqs: %d' % len(single_mismatches))\n",
    "\n",
    "single_insertions = fbseqtools.get_insertion_seqs(target, 1)\n",
    "sequence_set.update(single_insertions)\n",
    "log.info('Single insertion seqs: %d' % len(single_insertions))\n",
    "\n",
    "single_deletions = fbseqtools.get_deletion_seqs(target, 1)\n",
    "sequence_set.update(single_deletions)\n",
    "log.info('Single deletion seqs: %d' % len(single_deletions))\n",
    "\n",
    "# Every stretch of mismatched sequence at each possible position in the target\n",
    "c_stretch = set()\n",
    "for stretch_size in range(2, len(target) + 1):\n",
    "    complement_stretch = fbseqtools.get_stretch_of_complement_seqs(target, stretch_size)\n",
    "    c_stretch |= complement_stretch\n",
    "sequence_set.update(c_stretch)\n",
    "log.info('Complement stretch seqs: %d' % len(c_stretch))\n",
    "\n",
    "# PAMs with perfect target\n",
    "#randomized_pams = set()\n",
    "#for seq in fbseqtools.get_randomized_pam_seqs(target, 4, 5, '5p'):\n",
    "#    randomized_pams.add('A' + seq)\n",
    "#    if simple_hamming_distance(seq[1: 4], 'TTT') <= 1:\n",
    "#        for base in bases:\n",
    "#            randomized_pams.add(base + seq[1:])\n",
    "#randomized_pams |= fbseqtools.get_randomized_pam_seqs(target, 3, 5, '3p')\n",
    "#sequence_set.update(randomized_pams)\n",
    "#log.info('6N PAMs: %d' % len(randomized_pams))\n",
    "\n",
    "# Perfect Targets A-E and A-Csy\n",
    "other_targets = set(targets.values())\n",
    "log.info('Alternative targets: %d' % len(other_targets))\n",
    "sequence_set.update(other_targets)\n",
    "\n",
    "# double mismatches, deletions, and insertions \n",
    "double_mismatch_sequences = fbseqtools.get_mismatch_seqs(target, 2)\n",
    "sequence_set.update(double_mismatch_sequences)\n",
    "log.info('Double mismatch seqs: %d' % len(double_mismatch_sequences))\n",
    "\n",
    "double_deletions = fbseqtools.get_deletion_seqs(target, 2)\n",
    "log.info('Double deletion seqs: %d' % len(double_deletions))\n",
    "sequence_set.update(double_deletions)\n",
    "\n",
    "double_insertion_sequences = fbseqtools.get_insertion_seqs(target, 2)\n",
    "log.info('Double insertion seqs: %d' % len(double_insertion_sequences))\n",
    "sequence_set.update(double_insertion_sequences)\n",
    "\n",
    "# Generate complete sequences from collected sequences\n",
    "complete_sequences = set()\n",
    "for sequence in sequence_set:\n",
    "    left_barcode, right_barcode = barcode_pairs.pop()\n",
    "    complete_sequences.add(NucleaSeqOligo(cr1, left_barcode, buffer1, sequence, buffer2, '', right_barcode, cr2))\n",
    "    \n",
    "# Perfect target with different buffer regions    \n",
    "alt_buffers = set([(buffer, buffer[::-1]) for buffer in fbseqtools.get_randomized_stretch_seqs(buffer1, 2)\n",
    "                   if 'AAA' not in buffer and 'CCC' not in buffer and 'GGG' not in buffer and 'TTT' not in buffer\n",
    "                   and buffer.startswith(buffer1[:3])])\n",
    "good_gc_alt_buffers = set()\n",
    "for a, b in alt_buffers:\n",
    "    gc_content = float(a.count('C') + a.count('G')) / len(a)\n",
    "    if gc_content <= 0.6:\n",
    "        good_gc_alt_buffers.add((a, b))\n",
    "for left_buffer, right_buffer in good_gc_alt_buffers:\n",
    "    left_barcode, right_barcode = barcode_pairs.pop()\n",
    "    complete_sequences.add(NucleaSeqOligo(cr1, left_barcode, left_buffer, target, right_buffer, '', right_barcode, cr2))\n",
    "log.info('Alternative buffer with perfect target seqs: %d' % len(good_gc_alt_buffers))\n",
    "\n",
    "# Perfect target with various barcodes\n",
    "log.info('Perfect target with different barcode seqs: %d' % min_perfect_target_copies)\n",
    "for _ in range(min_perfect_target_copies):\n",
    "    left_barcode, right_barcode = barcode_pairs.pop()\n",
    "    complete_sequences.add(NucleaSeqOligo(cr1, left_barcode, buffer1, target, buffer2, '', right_barcode, cr2))\n",
    "\n",
    "\n",
    "# Error rate detection sequences    \n",
    "len_err_detect_seq = (\n",
    "    max(len(seq) for seq in complete_sequences) \n",
    "    - sum(len(s) for s in [cr1, left_barcode, '', right_barcode, cr2])\n",
    ")\n",
    "err_detect_seqs = generate_clean_random_eqmarg_seqs(nseq=n_err_detect_seqs,\n",
    "                                                    seqlen=len_err_detect_seq)\n",
    "err_min_dists = [min_dist_to_target_seed(seq) for seq in err_detect_seqs]\n",
    "log.info('Before search min error detection seq dist to target seed quartiles: {} / {} / {} / {} / {}'.format(\n",
    "    *map(int, np.percentile(err_min_dists, [0, 25, 50, 75, 100]))\n",
    "))\n",
    "\n",
    "for _ in range(50):\n",
    "    test_err_detect_seqs = generate_clean_random_eqmarg_seqs(nseq=n_err_detect_seqs,\n",
    "                                                             seqlen=len_err_detect_seq)\n",
    "    if (min(min_dist_to_target_seed(seq) for seq in test_err_detect_seqs)\n",
    "        > min(min_dist_to_target_seed(seq) for seq in err_detect_seqs)):\n",
    "        err_detect_seqs = test_err_detect_seqs\n",
    "        \n",
    "err_min_dists = [min_dist_to_target_seed(seq) for seq in err_detect_seqs]\n",
    "log.info('After search min error detection seq dist to target seed quartiles: {} / {} / {} / {} / {}'.format(\n",
    "    *map(int, np.percentile(err_min_dists, [0, 25, 50, 75, 100]))\n",
    "))\n",
    "log.info('Error detection seqs: %d' % len(err_detect_seqs))\n",
    "        \n",
    "for err_seq in err_detect_seqs:\n",
    "    left_barcode, right_barcode = err_barcode_pairs.pop()\n",
    "    complete_sequences.add(NucleaSeqOligo(cr1, left_barcode, '', err_seq, '', '', right_barcode, cr2))\n",
    "\n",
    "    \n",
    "#----------------------------------------------------------------------------------\n",
    "# Fill unused seqs\n",
    "#----------------------------------------------------------------------------------\n",
    "\n",
    "log.info('Remaining seqs to be filled: {}'.format(total_desired_seqs - len(complete_sequences)))\n",
    "num_singles = len(single_deletions) + len(single_insertions) + len(single_mismatches)\n",
    "singleton_copies = 1\n",
    "while total_desired_seqs - len(complete_sequences) > num_singles:\n",
    "    singleton_copies += 1\n",
    "    for sequence in single_deletions | single_insertions | single_mismatches:\n",
    "        left_barcode, right_barcode = barcode_pairs.pop()\n",
    "        complete_sequences.add(NucleaSeqOligo(cr1, left_barcode, buffer1, sequence, buffer2, '', right_barcode, cr2))\n",
    "log.info('Total copies/sequences of single error seqs: {}/{}'.format(singleton_copies, singleton_copies*num_singles))\n",
    "\n",
    "added_perfects = 0\n",
    "while total_desired_seqs > len(complete_sequences):\n",
    "    added_perfects += 1\n",
    "    left_barcode, right_barcode = barcode_pairs.pop()\n",
    "    complete_sequences.add(NucleaSeqOligo(cr1, left_barcode, buffer1, target, buffer2, '', right_barcode, cr2))\n",
    "log.info('Added perfect seqs: {}'.format(added_perfects))\n",
    "log.info('Total perfect seqs: {}'.format(added_perfects \n",
    "                                              + min_perfect_target_copies\n",
    "                                              + len(good_gc_alt_buffers)))\n",
    "    \n",
    "log.info('Total sequences generated: %d' % len(complete_sequences))\n",
    "if barcode_pairs:\n",
    "    log.warning('\\n(%d unused barcode pairs)\\n' % len(barcode_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example oligo (107 bp):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['AGATCGCAGCTCGTCAAT',\n",
       " 'ATTCATGTTCCTCAAGC',\n",
       " 'ATCGA',\n",
       " 'TTTAGTGATAAGTGGAATGCCCTGTGG',\n",
       " 'ATGCA',\n",
       " '',\n",
       " 'AGACGTACTGCTGCGCT',\n",
       " 'CGTCATAATGAACGCGCT']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oligo = list(complete_sequences)[0]\n",
    "print 'Example oligo ({} bp):'.format(len(oligo))\n",
    "oligo.pieces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0% of sequences have unusually high or low GC content\n"
     ]
    }
   ],
   "source": [
    "bad_gc_seqs = [seq for seq in complete_sequences if seq.gc_content >= 0.6 or seq.gc_content <= 0.4]\n",
    "print '{:.1f}% of sequences have unusually high or low GC content'.format(100*float(len(bad_gc_seqs))/len(complete_sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of seqs, barcodes: 12472\n"
     ]
    }
   ],
   "source": [
    "left_bcs = set(oligo._barcode_left for oligo in complete_sequences)\n",
    "right_bc_rcs = set(str(Seq(oligo._barcode_right).reverse_complement()) for oligo in complete_sequences)\n",
    "assert len(left_bcs) == len(right_bc_rcs)\n",
    "print 'Number of seqs, barcodes:', len(left_bcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw oligos range in length from 103 nt to 115 nt\n"
     ]
    }
   ],
   "source": [
    "raw_oligo_lens = set(map(len, complete_sequences))\n",
    "print 'Raw oligos range in length from {} nt to {} nt'.format(min(raw_oligo_lens), max(raw_oligo_lens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Primers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oligo lengths: set([138])\n"
     ]
    }
   ],
   "source": [
    "random.seed(rand_seeds[9])\n",
    "complete_sequences = design.update_buffers(\n",
    "    complete_sequences, \n",
    "    min_primer_len, \n",
    "    min_buffer_len,\n",
    "    target,\n",
    "    bad_substrs,\n",
    "    fudge_factor,\n",
    "    abs_cannonical_cut_sites,\n",
    "    pamtarg_coord_one_pos\n",
    ")\n",
    "\n",
    "print 'Oligo lengths:', set(map(len, complete_sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example oligo:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['AGATCGCAGCTCGTCAAT',\n",
       " 'ATTCATGTTCCTCAAGC',\n",
       " 'CACTGA',\n",
       " 'TTTAGTGATAAGTGGAATGCCCTGTGG',\n",
       " 'TAGAGTACTAGCGAGCTATCTGCGCAC',\n",
       " 'GCTCGAAT',\n",
       " 'AGACGTACTGCTGCGCT',\n",
       " 'CGTCATAATGAACGCGCT']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oligo = list(complete_sequences)[0]\n",
    "print 'Example oligo:'\n",
    "oligo.pieces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find usable primer prefixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying 21\n",
      "Oligo lengths: set([138])\n",
      "Left/right buffers: CATGCA / TCGACATGCAGCGACTGCTAGTACTAG\n",
      ".\n",
      "Trying 22\n",
      "Oligo lengths: set([140])\n",
      "Left/right buffers: CGCATGA / TAGTAGCTCACGACTACTGCAGTGCAGT\n",
      ".*******\n",
      "Success!\n",
      "['GCGTTGTTCGAGCTGTTGCGTT', 'AATGTGTTCGCTTCGTTGTTGT', 'TTCGCGCTGTAAGAGTGTGTTG', 'GCTGCAACTCAATGTAACTGTG', 'TCTTCTTGCTGTTCTTGTTACG', 'AACTCTATCTTCACGTCTTCGA', 'GAGCGAGCGACAAGCGTGCAAT']\n",
      "\n",
      "['GCGTTGTTCGAGCTGTTGCGTT', 'AATGTGTTCGCTTCGTTGTTGT', 'TTCGCGCTGTAAGAGTGTGTTG', 'GCTGCAACTCAATGTAACTGTG', 'TCTTCTTGCTGTTCTTGTTACG', 'AACTCTATCTTCACGTCTTCGA', 'GAGCGAGCGACAAGCGTGCAAT']\n"
     ]
    }
   ],
   "source": [
    "for primer_len in range(min_primer_len, max_primer_len + 1):\n",
    "    print 'Trying', primer_len\n",
    "    random.seed(rand_seeds[3])\n",
    "    complete_sequences = design.update_buffers(\n",
    "        complete_sequences, \n",
    "        primer_len, \n",
    "        min_buffer_len,\n",
    "        target,\n",
    "        bad_substrs,\n",
    "        fudge_factor,\n",
    "        abs_cannonical_cut_sites,\n",
    "        pamtarg_coord_one_pos\n",
    "    )\n",
    "    print 'Oligo lengths:', set(map(len, complete_sequences))\n",
    "    oligo = list(complete_sequences)[0]\n",
    "    print 'Left/right buffers: {} / {}'.format(oligo._buffer_left, oligo._buffer_right)\n",
    "    \n",
    "    good_prefixes = design.find_good_prefixes(\n",
    "        complete_sequences, \n",
    "        primer_len, \n",
    "        bad_substrs,\n",
    "        cannonical_cut_sites,\n",
    "        fudge_factor,\n",
    "        nprocs\n",
    "    )\n",
    "    if len(good_prefixes) >= 2:\n",
    "        break\n",
    "    print \n",
    "\n",
    "assert len(good_prefixes) >= 2\n",
    "print\n",
    "print 'Success!'\n",
    "print good_prefixes\n",
    "print\n",
    "\n",
    "if primer_len == min_primer_len:\n",
    "    prev_good_prefixes = good_prefixes[:]\n",
    "    for fake_primer_len in range(primer_len-1, 0, -1):\n",
    "        print 'Trying buffers based on', fake_primer_len\n",
    "        random.seed(rand_seeds[3])\n",
    "        complete_sequences = design.update_buffers(\n",
    "            complete_sequences, \n",
    "            fake_primer_len, \n",
    "            min_buffer_len,\n",
    "            target,\n",
    "            bad_substrs,\n",
    "            fudge_factor,\n",
    "            abs_cannonical_cut_sites,\n",
    "            pamtarg_coord_one_pos\n",
    "        )\n",
    "        print 'Oligo lengths:', set(map(len, complete_sequences))\n",
    "        oligo = list(complete_sequences)[0]\n",
    "        print 'Left/right buffers: {} / {}'.format(oligo._buffer_left, oligo._buffer_right)\n",
    "\n",
    "        good_prefixes = design.find_good_prefixes(\n",
    "            complete_sequences, \n",
    "            primer_len, \n",
    "            bad_substrs,\n",
    "            cannonical_cut_sites,\n",
    "            fudge_factor,\n",
    "            nprocs\n",
    "        )\n",
    "        if len(good_prefixes) >= 2:\n",
    "            print\n",
    "            print good_prefixes\n",
    "            prev_good_prefixes = good_prefixes[:]\n",
    "        else:\n",
    "            break\n",
    "        print \n",
    "    print\n",
    "    print 'Failed, reverting to best previous:'\n",
    "    good_prefixes = prev_good_prefixes\n",
    "    fake_primer_len += 1\n",
    "print good_prefixes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replace primers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the above primers in your oligo analyzer of choice. If your experimental conditions require a longer primer, add bases as desired below. If you need shorter primers, do not change anything here. The full length of these primers is needed for the post-experiment analysis. Simply order primers with the inner bases removed as needed for your experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left / Right primers:\n",
      "GCGTTGTTCGAGCTGTTGCGTT\n",
      "AATGTGTTCGCTTCGTTGTTGTG\n",
      "\n",
      "Hence, the oligos will have the form:\n",
      "\n",
      "GCGTTGTTCGAGCTGTTGCGTT    BC_left/Buf_left/Target/Buf_right/BC_right*    CACAACAACGAAGCGAACACATT\n"
     ]
    }
   ],
   "source": [
    "left_primer = good_prefixes[0] + ''\n",
    "right_primer = good_prefixes[1] + 'G'\n",
    "cr_left = left_primer\n",
    "cr_right = fbseqtools.dna_rev_comp(right_primer)\n",
    "\n",
    "print 'Left / Right primers:'\n",
    "print left_primer\n",
    "print right_primer\n",
    "print\n",
    "print 'Hence, the oligos will have the form:'\n",
    "print\n",
    "print '{}    BC_left/Buf_left/Target/Buf_right/BC_right*    {}'.format(cr_left, cr_right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for oligo in complete_sequences:\n",
    "    oligo._cr_left = cr_left\n",
    "    oligo._cr_right = cr_right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oligo lengths: set([149])\n"
     ]
    }
   ],
   "source": [
    "print 'Oligo lengths:', set(map(len, complete_sequences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seq_fpath = 'target_{}_seqs.txt'.format(target_name)\n",
    "exploded_seq_fpath = 'exploded_' + seq_fpath\n",
    "\n",
    "with open(seq_fpath, 'w') as out:\n",
    "    out.write('\\n'.join([oligo.sequence for oligo in complete_sequences]))\n",
    "with open(exploded_seq_fpath, 'w') as out:\n",
    "    out.write('\\n'.join([oligo.tab_delimited_str() for oligo in complete_sequences]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_time = time.time() - notebook_start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run time: 2123.42604494 seconds\n"
     ]
    }
   ],
   "source": [
    "print 'Run time: {} seconds'.format(total_time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NucleaSeq",
   "language": "python",
   "name": "nucleaseq"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
