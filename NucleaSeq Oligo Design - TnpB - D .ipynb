{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oligo Design\n",
    "\n",
    "For Nucleaseq, we want to design sequences with the following basic structure:\n",
    "\n",
    "| Left primer | Left BC | Left buffer | Target$_n$ | Right buffer | Right fill | Right BC | Right primer |\n",
    "| - | - | - | - | - | - | - | - |\n",
    "\n",
    "Where Target$_n$ is from the set of all desired modified target sequences. \n",
    "\n",
    "The set of Target$_n$'s is specific to each experiment, but there are some relatively standard sets. For example, most experiments will wish to include all single- and double-mismatch sequences. While on the other hand, the PAM structure for each CRISPR variant is different and may require custom sequence generation. And other nucleases may have entirely different needs.\n",
    "\n",
    "To handle this, we have a number of functions for standard modifications in design.py, which can be called below, while at the same time we have a space explicitly reserved for custom sequence generation: \"Custom sequence functions\". After the set of target-generation functions is complete, they need added to the \"Construct Sequences\" section below, in the manner shown by the included examples. Go through this section carefully to verify the set of included sequences is correct.\n",
    "\n",
    "The \"Run parameters\" section needs updated according to the experimental requirements, as well. One parameter which needs specified is a list all canonical cut positions along the target sequence. This needs to be a python integer with \".5\" after it to indicate the cut position. For instance, 18.5 cuts between python indices 18 and 19. The lower portion of this notebook needs this information to find appropriate primer sequences.\n",
    "\n",
    "Finally, the user is expected to adjust the primers as necessary to fit their experimental conditions. See the \"Replace Primers\" section for details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequence Motifs\n",
    "\n",
    "### For this notebook, we want the following sequences and modifications:\n",
    "\n",
    "* Target D - TnpB (IsDra2)\n",
    "* single mismatches\n",
    "* double mismatches\n",
    "* single insertions\n",
    "* double insertions\n",
    "* single deletions \n",
    "* double deletions\n",
    "* scanning mismatch regions (using the complement) for 3 bp to 24 bp length regions\n",
    "* Perfect target with different buffer regions\n",
    "* Perfect target with various barcodes\n",
    "* Random negative control seqs\n",
    "* Various 5N PAM\n",
    "* single mm and single ins seqs\n",
    "* single mm and single del seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "notebook_start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import yaml\n",
    "import itertools\n",
    "import random\n",
    "import math\n",
    "import logging\n",
    "import scipy.misc\n",
    "import editdistance\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from collections import defaultdict, Counter\n",
    "from Bio.Seq import Seq\n",
    "from freebarcodes.seqtools import simple_hamming_distance\n",
    "import freebarcodes.seqtools as fbseqtools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nucleaseq import design, seqtools\n",
    "from nucleaseq.NucleaSeqOligo import NucleaSeqOligo\n",
    "from nucleaseq.equalmarginalseqs import generate_clean_random_eqmarg_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import freebarcodes. Need to show jupyter where to find it.\n",
    "sys.path.append('/home/joneslab/nucleaseq/freebarcodes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_seed = 37\n",
    "random.seed(master_seed)\n",
    "rand_seeds = [random.randint(0, 100) for i in range(10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What library size do You desire? Defaut: 12472\n",
      "How many negative control sequences? Default: 150\n",
      "How many perfect targets do You desire? Default: 50\n",
      "What bases make up Your genetic code? Default: ACGTacgt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The provided barcodes file has 64521 barcodes, which could create 32260 barcode pairs. It is important that the      amount of barcode pairs is not less than 12472- the total_desired_seqs\n",
      "The provided barcodes file has 64521 barcodes, which could create 32260 barcode pairs. It is important that the      amount of barcode pairs is not less than 12472- the total_desired_seqs\n",
      "The provided barcodes file has 64521 barcodes, which could create 32260 barcode pairs. It is important that the      amount of barcode pairs is not less than 12472- the total_desired_seqs\n",
      "The provided barcodes file has 64521 barcodes, which could create 32260 barcode pairs. It is important that the      amount of barcode pairs is not less than 12472- the total_desired_seqs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACGT\n"
     ]
    }
   ],
   "source": [
    "# Library features\n",
    "total_desired_seqs = int(raw_input('What library size do You desire? Defaut: 12472') or '12472')\n",
    "n_err_detect_seqs = int(raw_input('How many negative control sequences? Default: 150') or '150')\n",
    "min_perfect_target_copies = int(raw_input('How many perfect targets do You desire? Default: 50') or '50')\n",
    "base = raw_input('What bases make up Your genetic code? Default: ACGT') or 'ACGT'\n",
    "bases = base.upper()\n",
    "\n",
    "# Target features\n",
    "targets_fpath = '/home/joneslab/nucleaseq/resources/targets.yml'#TnpB-targets.yml'\n",
    "target_name = 'D'\n",
    "target_pam = 'TTTA'\n",
    "interesting_pams = ['TTTA'] # PAMs to investigate if you're interested in them. Originally: 'NNGAN'\n",
    "\n",
    "#Barcode features\n",
    "barcodes_fpath = '/home/joneslab/nucleaseq/freebarcodes/barcodes/barcodes18-2.txt'#barcodes17-2.txt'#_subset1of3.txt'\n",
    "barcodes = [line.strip() for line in open(barcodes_fpath)]\n",
    "bad_substrs = [target_pam, 'ATCAA'] # Forbidden subseqs in buffers or primers (here TnpB TAMs)\n",
    "\n",
    "# Primer features\n",
    "min_primer_len = 18  # First length to try. Will go smaller if possible. Adjust this if notebook too slow.\n",
    "max_primer_len = 25\n",
    "\n",
    "#Computational limits\n",
    "nprocs = 2 #20 #Is this the number of processors used for computation\n",
    "\n",
    "log = logging.getLogger()\n",
    "log.addHandler(logging.StreamHandler())\n",
    "log.setLevel(logging.INFO)\n",
    "log.info('The provided barcodes file has {} barcodes, which could create {} barcode pairs. It is important that the      amount of barcode pairs is not less than {}- the total_desired_seqs'.format(len(barcodes), len(barcodes)/2, total_desired_seqs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consider cut sites within 5 bp of pamtarg positions: [13, 22]\n",
      "Target D (27 bp): TTTAGTGATAAGTGGAATGCCATGTGG\n",
      "Target seeds:\n",
      "    (12 bp): TTTAGTGATAAG\n",
      "Cannonical cut sites:\n",
      "    TTTAGTGATAAGTGGAA x TGCCATGTGG\n",
      "    TTTAGTGATAAGTGGAATGCCATGTG x G\n"
     ]
    }
   ],
   "source": [
    "# Load the file containing the targets used for library generation.\n",
    "targets = yaml.safe_load(open(targets_fpath))\n",
    "target = targets[target_name]\n",
    "target_seeds = [target[:12]]\n",
    "h_cannonical_cut_sites = [16.5, 25.5]  # Include all cut sites on all strands, absolute coordinates\n",
    "fudge_factor = 5             # How far from a cannonical cut site are possible cuts\n",
    "min_buffer_len = 5           # Min length of target-flanking buffers\n",
    "\n",
    "pamtarg_coord_one_pos = 4   # Position in the target sequence just to the right of the PAM-target boundary\n",
    "abs_cannonical_cut_sites = [int(math.ceil(ccs)) for ccs in h_cannonical_cut_sites]\n",
    "cannonical_cut_sites = [ccs - pamtarg_coord_one_pos for ccs in abs_cannonical_cut_sites] # convert to pamtarg coords\n",
    "\n",
    "print 'Consider cut sites within {} bp of pamtarg positions: {}'.format(fudge_factor, cannonical_cut_sites)\n",
    "print 'Target {} ({} bp): {}'.format(target_name, len(target), target)\n",
    "print 'Target seeds:'\n",
    "for target_seed in target_seeds:\n",
    "    print '    ({} bp): {}'.format(len(target_seed), target_seed)\n",
    "print 'Cannonical cut sites:'\n",
    "for ccs in h_cannonical_cut_sites:\n",
    "    ccs = int(math.ceil(ccs))\n",
    "    print '    {} x {}'.format(target[:ccs], target[ccs:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Static Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temp left/right buffers: CAGAT TGGATC\n",
      "Temp primer 1: 19 bp, 47.4% GC  AACCGCCGAATAACAGAGT\n",
      "Temp primer 2 (rev_comp): 18 bp, 55.6% GC  AGTGTGCGAGGCGTTCTT\n"
     ]
    }
   ],
   "source": [
    "# Create primers (cr1,cr2) with a length of 19bp that avoids bad_substrs (PAM sequences, defined above).\n",
    "# Should be tested experimentally before purchasing (experience shows some primers (D) work better than others (E).\n",
    "#random.seed(rand_seeds[7])\n",
    "#cr1 = design.shuffled_equalish_bases(19, bad_substrs)\n",
    "#cr2 = design.shuffled_equalish_bases(19, bad_substrs)\n",
    "\n",
    "#Define primers that are known to amplify well:\n",
    "cr1 = 'AACCGCCGAATAACAGAGT' #NP1\n",
    "cr2 = str(Seq('AAGAACGCCTCGCACACT').reverse_complement())  #NP2\n",
    "\n",
    "# create buffers (buffer1,buffer2) that avoid bad_substrs (PAM sequences, defined above)\n",
    "buffer1 = \"CAGAT\"\n",
    "buffer2 = \"TGGATC\"\n",
    "#buffer1 = design.get_buffer(5, 'left', target, bad_substrs)\n",
    "#buffer2 = design.get_buffer(5, 'right', target, bad_substrs)\n",
    "\n",
    "print 'Temp left/right buffers:', buffer1, buffer2\n",
    "print 'Temp primer 1: {} bp, {:.1f}% GC  {}'.format(len(cr1), \n",
    "                                               100*(cr1.count('C') + cr1.count('G'))/float(len(cr1)),\n",
    "                                               cr1)\n",
    "print 'Temp primer 2 (rev_comp): {} bp, {:.1f}% GC  {}'.format(len(cr2), \n",
    "                                               100*(cr2.count('C') + cr2.count('G'))/float(len(cr2)),\n",
    "                                               cr2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generation of Sequences for Pilot Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom sequence functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pams(interesting_pams):\n",
    "    #################################################################\n",
    "    # This function generates all possible PAMs by substituting Ns  #\n",
    "    # with A,C,G and T for all the PAMs included in the input list. #\n",
    "    #################################################################\n",
    "    \n",
    "    assert type(interesting_pams) == list, \"The input must be a list.\"    \n",
    "    output_pams = [] # Empty list where all the possible PAMs will be added.\n",
    "    \n",
    "    # Iterate over each PAM in the input list.\n",
    "    for pam in interesting_pams:          \n",
    "        assert set(pam).issubset(set('ACGTN')), \"PAMs must be strings that only contain As,Cs,Gs,Ts and/or Ns.\"\n",
    "        \n",
    "        #Find the positions of all Ns in the PAM.\n",
    "        interesting_positions = []        \n",
    "        for i,value in enumerate(pam):    \n",
    "            if value == 'N': interesting_positions.append(i)\n",
    "                \n",
    "        #Replace Ns with all possible combinations of A, C, G and T.\n",
    "        for n in itertools.product(bases, repeat=len(interesting_positions)):\n",
    "            pam_temp = pam\n",
    "            for i,pos in enumerate(interesting_positions):\n",
    "                pam_temp = pam_temp[:pos]+n[i]+pam_temp[pos+1:]    \n",
    "            output_pams.append(pam_temp)  #Add the new PAMs to the list.\n",
    "            \n",
    "    return output_pams\n",
    "\n",
    "\n",
    "\n",
    "def get_interesting_pam_seqs(interesting_pams,target,pam):\n",
    "    \n",
    "    #####################################################################################\n",
    "    # This function outputs all targets with the PAMs from the 'interesting_pams' list. #\n",
    "    #####################################################################################   \n",
    "    output_seqs=[]\n",
    "    pams = get_pams(interesting_pams)\n",
    "    \n",
    "    #Replace the indicated PAM in the target with an interesting PAM\n",
    "    #whether it is at the beginning...\n",
    "    if target.startswith(pam):\n",
    "        target=target[len(pam):]\n",
    "        for pam in pams:\n",
    "            output_seqs.append(pam+target)\n",
    "            \n",
    "    #or the end of the target.      \n",
    "    elif target.endswith(pam):\n",
    "        target=target[:(len(target)-len(pam))]\n",
    "        for pam in pams:\n",
    "            output_seqs.append(target+pam)  \n",
    "            \n",
    "    else:\n",
    "        raise Exception('A target must end or begin with the PAM.')\n",
    "    \n",
    "    return output_seqs\n",
    "\n",
    "\n",
    "####---------------------------------------------------------------####\n",
    "def next_different_base(samp):\n",
    "    samp_bases = set(samp)\n",
    "    assert len(samp_bases) < 4, samp\n",
    "    for b in bases:\n",
    "        if b not in samp_bases:\n",
    "            return b\n",
    "\n",
    "\n",
    "def get_one_mm_seq_per_pos(seq):\n",
    "    output = set()\n",
    "    for i in range(len(seq)):\n",
    "        # Choose mismatch to be different from ref base and neighboring bases\n",
    "        neighborhood = seq[max(i-1, 0):i+2]\n",
    "        assert len(neighborhood) == 3 or i == 0 or i == len(seq) - 1, (i, neighborhood)\n",
    "        output.add(seq[:i] + next_different_base(neighborhood) + seq[i+1:])\n",
    "    return output \n",
    "\n",
    "\n",
    "def get_one_ins_seq_per_pos(seq):\n",
    "    output = set()\n",
    "    for i in range(len(seq)):\n",
    "        # Choose insertion to be different from either neighboring base\n",
    "        neighborhood = seq[max(i-1, 0):i+1]\n",
    "        assert len(neighborhood) == 2 or i == 0, (i, neighborhood)\n",
    "        output.add(seq[:i] + next_different_base(neighborhood) + seq[i:])\n",
    "    return output\n",
    "\n",
    "\n",
    "def get_single_mm_single_del_seqs():\n",
    "    output = set()\n",
    "    for del_seq in fbseqtools.get_deletion_seqs(target, 1):\n",
    "        output.update(get_one_mm_seq_per_pos(del_seq))\n",
    "    return output\n",
    "\n",
    "\n",
    "def get_single_mm_single_ins_seqs():\n",
    "    output = set()\n",
    "    for mm_seq in get_one_mm_seq_per_pos(target):\n",
    "        output.update(get_one_ins_seq_per_pos(mm_seq))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell is the heart of the sequence construction. It is a single cell to \n",
    "# guarantee all parts are always performed together, so make reproducible output.\n",
    "\n",
    "#----------------------------------------------------------------------------------\n",
    "# Setup the barcode pairs\n",
    "#----------------------------------------------------------------------------------\n",
    "\n",
    "def min_dist_to_target_seed(s):\n",
    "    #This function makes sure that the barcodes are not too similar to the seed.\n",
    "    #It's problematic because it depends on global variables from elsewhere in the notebook.\n",
    "    min_dists = []\n",
    "    for target_seed in target_seeds:\n",
    "        if len(s) > len(target_seed):\n",
    "            slong, sshort = s, target_seed\n",
    "        else:\n",
    "            slong, sshort = target_seed, s\n",
    "        slong_rc = seqtools.dna_rev_comp(slong)\n",
    "        min_dists.append(min(editdistance.eval(sshort, sl[i:i+len(sshort)]) \n",
    "                             for i in range(len(slong) - len(sshort) + 1)\n",
    "                             for sl in [slong, slong_rc]))\n",
    "    return min(min_dists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Max / min accepted / min barcode distances to target seed: 9 / 7 / 2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "barcodes.sort(key=min_dist_to_target_seed, reverse=True) # Prefer barcodes disimilar to target seed\n",
    "err_barcodes = barcodes[:n_err_detect_seqs]\n",
    "norm_barcodes = barcodes[n_err_detect_seqs:total_desired_seqs]\n",
    "log.info('Max / min accepted / min barcode distances to target seed: {} / {} / {}\\n'.format(\n",
    "    min_dist_to_target_seed(err_barcodes[0]),\n",
    "    min_dist_to_target_seed(norm_barcodes[-1]),\n",
    "    min_dist_to_target_seed(barcodes[-1])\n",
    "))\n",
    "\n",
    "random.seed(rand_seeds[2])\n",
    "random.shuffle(norm_barcodes)\n",
    "random.shuffle(err_barcodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "barcode_pairs, err_barcode_pairs = [], []\n",
    "for i in xrange(len(norm_barcodes)):\n",
    "    bc1 = norm_barcodes[i]\n",
    "    i2 = (i+1) % len(norm_barcodes)\n",
    "    bc2_rc = str(Seq(norm_barcodes[i2]).reverse_complement())\n",
    "    barcode_pairs.append((bc1, bc2_rc))\n",
    "\n",
    "for i in xrange(len(err_barcodes)):\n",
    "    bc1 = err_barcodes[i]\n",
    "    i2 = (i+1) % len(err_barcodes)\n",
    "    bc2_rc = str(Seq(err_barcodes[i2]).reverse_complement())\n",
    "    err_barcode_pairs.append((bc1, bc2_rc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Interesting PAM seqs: 1\n",
      "Single mismatch seqs: 81\n",
      "Single insertion seqs: 82\n",
      "Single deletion seqs: 20\n",
      "Complement stretch seqs: 351\n",
      "Double mismatch seqs: 3159\n",
      "Double deletion seqs: 191\n",
      "Double insertion seqs: 2622\n"
     ]
    }
   ],
   "source": [
    "#----------------------------------------------------------------------------------\n",
    "# Custom sequences\n",
    "#----------------------------------------------------------------------------------\n",
    "\n",
    "sequence_set = set()\n",
    "\n",
    "# Interesting PAMs\n",
    "interesting_pam_seqs = get_interesting_pam_seqs(interesting_pams,target,target_pam)\n",
    "sequence_set.update(interesting_pam_seqs)\n",
    "log.info('Interesting PAM seqs: {}'.format(len(interesting_pam_seqs)))\n",
    "\n",
    "# Single mm and single del\n",
    "#single_mm_single_del_sequences = get_single_mm_single_del_seqs()\n",
    "#log.info('Single mm, Single del seqs: %d' % len(single_mm_single_del_sequences))\n",
    "#sequence_set.update(single_mm_single_del_sequences)\n",
    "\n",
    "# Single mm and single ins\n",
    "#single_mm_single_ins_sequences = get_single_mm_single_ins_seqs()\n",
    "#log.info('Single mm, Single ins seqs: %d' % len(single_mm_single_ins_sequences))\n",
    "#sequence_set.update(single_mm_single_ins_sequences)\n",
    "\n",
    "\n",
    "#----------------------------------------------------------------------------------\n",
    "# Standard sequences\n",
    "#----------------------------------------------------------------------------------\n",
    "\n",
    "#This is static if we dont change the target\n",
    "\n",
    "# All possible single mismatches and indels\n",
    "single_mismatches = fbseqtools.get_mismatch_seqs(target, 1)\n",
    "sequence_set.update(single_mismatches)\n",
    "log.info('Single mismatch seqs: %d' % len(single_mismatches))\n",
    "\n",
    "single_insertions = fbseqtools.get_insertion_seqs(target, 1)\n",
    "sequence_set.update(single_insertions)\n",
    "log.info('Single insertion seqs: %d' % len(single_insertions))\n",
    "\n",
    "single_deletions = fbseqtools.get_deletion_seqs(target, 1)\n",
    "sequence_set.update(single_deletions)\n",
    "log.info('Single deletion seqs: %d' % len(single_deletions))\n",
    "\n",
    "# Every stretch of mismatched sequence at each possible position in the target\n",
    "###NOTE: Altered for TnpB to reduce library size.\n",
    "\n",
    "#Creates sequences that have a stretch of the same nukleotide (multiple G's one after the other) that are mispaired\n",
    "\n",
    "c_stretch = set()\n",
    "for stretch_size in range(2, len(target) + 1):\n",
    "    complement_stretch = fbseqtools.get_stretch_of_complement_seqs(target, stretch_size)\n",
    "    #NOTE: #Code to remove PAM from the stretch regions\n",
    "    #complement_stretch = list(complement_stretch)\n",
    "    #for i, seq in enumerate(complement_stretch):\n",
    "    #    complement_stretch[i] = target_pam+complement_stretch[i][len(target_pam):]\n",
    "    #complement_stretch = set(complement_stretch)\n",
    "    #End of code to remove PAM\n",
    "    c_stretch |= complement_stretch\n",
    "sequence_set.update(c_stretch)\n",
    "log.info('Complement stretch seqs: %d' % len(c_stretch))\n",
    "\n",
    "\n",
    "# double mismatches, deletions, and insertions \n",
    "double_mismatch_sequences = fbseqtools.get_mismatch_seqs(target, 2)\n",
    "sequence_set.update(double_mismatch_sequences)\n",
    "log.info('Double mismatch seqs: %d' % len(double_mismatch_sequences))\n",
    "double_deletions = fbseqtools.get_deletion_seqs(target, 2)\n",
    "log.info('Double deletion seqs: %d' % len(double_deletions)) #gives the text a red background\n",
    "sequence_set.update(double_deletions)\n",
    "\n",
    "#double_insertion_sequences = fbseqtools.get_insertion_seqs(target, 2)\n",
    "#Change code to limit sequences. \n",
    "double_insertion_sequences = list(fbseqtools.get_insertion_seqs(target[3:], 2))\n",
    "for i,sequence in enumerate(double_insertion_sequences): \n",
    "    double_insertion_sequences[i]=target_pam[:3]+sequence\n",
    "double_insertion_sequences = set(double_insertion_sequences)\n",
    "#End code change\n",
    "\n",
    "log.info('Double insertion seqs: %d' % len(double_insertion_sequences))\n",
    "sequence_set.update(double_insertion_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate complete sequences from collected sequences \n",
    "complete_sequences = set()\n",
    "barcode_pairs_copy = set(barcode_pairs)\n",
    "for sequence in sequence_set:\n",
    "    left_barcode, right_barcode = barcode_pairs_copy.pop()\n",
    "    complete_sequences.add(NucleaSeqOligo(cr1, left_barcode, buffer1, sequence, buffer2, '', right_barcode, cr2))\n",
    "    if len(complete_sequences) == total_desired_seqs - n_err_detect_seqs - min_perfect_target_copies: break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perfect target with different buffer regions    \n",
    "alt_buffers = set([(buffer, buffer[::-1]) for buffer in fbseqtools.get_randomized_stretch_seqs(buffer1, 2)\n",
    "               if 'AAA' not in buffer and 'CCC' not in buffer and 'GGG' not in buffer and 'TTT' not in buffer\n",
    "               and buffer.startswith(buffer1[:3])])\n",
    "\n",
    "\n",
    "#What portion of the DNA is made up of G's and C's\n",
    "good_gc_alt_buffers = set()\n",
    "for a, b in alt_buffers:\n",
    "    gc_content = float(a.count('C') + a.count('G')) / len(a)\n",
    "    if gc_content <= 0.6:\n",
    "        good_gc_alt_buffers.add((a, b))\n",
    "barcode_pairs_copy = set(barcode_pairs)\n",
    "for left_buffer, right_buffer in good_gc_alt_buffers:\n",
    "    left_barcode, right_barcode = barcode_pairs_copy.pop()\n",
    "    complete_sequences.add(NucleaSeqOligo(cr1, left_barcode, left_buffer, target, right_buffer, '', right_barcode, cr2))\n",
    "#    log.info('Alternative buffer with perfect target seqs: %d' % len(good_gc_alt_buffers))\n",
    "\n",
    "# Perfect target with various barcodes\n",
    "#    log.info('Perfect target with different barcode seqs: %d' % min_perfect_target_copies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "barcode_pairs_copy = set(barcode_pairs)\n",
    "for _ in range(min_perfect_target_copies):\n",
    "    left_barcode, right_barcode = barcode_pairs_copy.pop()\n",
    "    complete_sequences.add(NucleaSeqOligo(cr1, left_barcode, buffer1, target, buffer2, '', right_barcode, cr2))\n",
    "\n",
    "\n",
    "# Error rate detection sequences    \n",
    "len_err_detect_seq = (\n",
    "    max(len(seq) for seq in complete_sequences) \n",
    "    - sum(len(s) for s in [cr1, left_barcode, '', right_barcode, cr2])\n",
    ")\n",
    "err_detect_seqs = generate_clean_random_eqmarg_seqs(nseq=n_err_detect_seqs,\n",
    "                                                seqlen=len_err_detect_seq)\n",
    "err_min_dists = [min_dist_to_target_seed(seq) for seq in err_detect_seqs]\n",
    "#    log.info('Before search min error detection seq dist to target seed quartiles: {} / {} / {} / {} / {}'.format(\n",
    "#        *map(int, np.percentile(err_min_dists, [0, 25, 50, 75, 100]))\n",
    "#   ))\n",
    "\n",
    "\n",
    "for _ in range(50):\n",
    "    test_err_detect_seqs = generate_clean_random_eqmarg_seqs(nseq=n_err_detect_seqs,\n",
    "                                                         seqlen=len_err_detect_seq)\n",
    "    if (min(min_dist_to_target_seed(seq) for seq in test_err_detect_seqs)\n",
    "        > min(min_dist_to_target_seed(seq) for seq in err_detect_seqs)):\n",
    "        err_detect_seqs = test_err_detect_seqs\n",
    "        \n",
    "err_min_dists = [min_dist_to_target_seed(seq) for seq in err_detect_seqs]\n",
    "#    log.info('After search min error detection seq dist to target seed quartiles: {} / {} / {} / {} / {}'.format(\n",
    "#        *map(int, np.percentile(err_min_dists, [0, 25, 50, 75, 100]))\n",
    "#    ))\n",
    "#    log.info('Error detection seqs: %d' % len(err_detect_seqs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "err_barcode_pairs_copy = set(barcode_pairs)\n",
    "for err_seq in err_detect_seqs:\n",
    "    left_barcode, right_barcode = err_barcode_pairs_copy.pop()\n",
    "    complete_sequences.add(NucleaSeqOligo(cr1, left_barcode, '', err_seq, '', '', right_barcode, cr2))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Alternative buffer with perfect target seqs: 12\n",
      "Alternative buffer with perfect target seqs: 12\n",
      "Perfect target with different barcode seqs: 50\n",
      "Perfect target with different barcode seqs: 50\n",
      "Before search min error detection seq dist to target seed quartiles: 4 / 5 / 5 / 6 / 6\n",
      "Before search min error detection seq dist to target seed quartiles: 4 / 5 / 5 / 6 / 6\n",
      "After search min error detection seq dist to target seed quertiles: 4 / 5 / 5 / 6/ 6\n",
      "After search min error detection seq dist to target seed quertiles: 4 / 5 / 5 / 6/ 6\n",
      "Error detection seqs: 150\n",
      "Error detection seqs: 150\n"
     ]
    }
   ],
   "source": [
    "log.info('Alternative buffer with perfect target seqs: %d' % len(good_gc_alt_buffers))\n",
    "log.info('Perfect target with different barcode seqs: %d' % min_perfect_target_copies)\n",
    "log.info('Before search min error detection seq dist to target seed quartiles: {} / {} / {} / {} / {}'.format(\n",
    "    *map(int, np.percentile(err_min_dists, [0, 25, 50, 75, 100]))))\n",
    "log.info('After search min error detection seq dist to target seed quertiles: {} / {} / {} / {}/ {}'.format(\n",
    "    *map(int, np.percentile(err_min_dists, [0, 25, 50, 75, 100]))))\n",
    "log.info('Error detection seqs: %d' % len(err_detect_seqs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Remaining seqs to be filled: 5779\n",
      "Remaining seqs to be filled: 5779\n",
      "Added perfect seqs: 1\n",
      "Added perfect seqs: 1\n",
      "Total perfect seqs: 63\n",
      "Total perfect seqs: 63\n",
      "Total copies/sequences of single error seqs: 2/366\n",
      "Total copies/sequences of single error seqs: 2/366\n",
      "Total sequences generated: 7057\n",
      "Total sequences generated: 7057\n",
      "\n",
      "(12139 unused barcode pairs)\n",
      "\n",
      "\n",
      "(12139 unused barcode pairs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#----------------------------------------------------------------------------------\n",
    "# Fill unused seqs\n",
    "#----------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "#Will take time to complete\n",
    "\n",
    "barcode_pairs_copy = set(barcode_pairs)\n",
    "log.info('Remaining seqs to be filled: {}'.format(total_desired_seqs - len(complete_sequences)))\n",
    "num_singles = len(single_deletions) + len(single_insertions) + len(single_mismatches)\n",
    "singleton_copies = 1\n",
    "singleton_copies += 1\n",
    "for sequence in single_deletions | single_insertions | single_mismatches:\n",
    "    left_barcode, right_barcode = barcode_pairs_copy.pop()\n",
    "    complete_sequences.add(NucleaSeqOligo(cr1, left_barcode, buffer1, sequence, buffer2, '', right_barcode, cr2))\n",
    "    added_perfects = 0\n",
    "    added_perfects += 1\n",
    "    left_barcode, right_barcode = barcode_pairs.pop()\n",
    "    complete_sequences.add(NucleaSeqOligo(cr1, left_barcode, buffer1, target, buffer2, '', right_barcode, cr2))\n",
    "\n",
    "    \n",
    "log.info('Added perfect seqs: {}'.format(added_perfects))\n",
    "log.info('Total perfect seqs: {}'.format(added_perfects \n",
    "                                              + min_perfect_target_copies\n",
    "                                              + len(good_gc_alt_buffers)))\n",
    "log.info('Total copies/sequences of single error seqs: {}/{}'.format(singleton_copies, singleton_copies*num_singles))    \n",
    "log.info('Total sequences generated: %d' % len(complete_sequences))\n",
    "if len(barcode_pairs) > 0:\n",
    "    log.warning('\\n(%d unused barcode pairs)\\n' % len(barcode_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example oligo (111 bp):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['AACCGCCGAATAACAGAGT',\n",
       " 'AAGAACACCGATAGCGCC',\n",
       " 'CAGAT',\n",
       " 'TTTAGTGTTAAGTGAAATGCCATGTGG',\n",
       " 'TGGATC',\n",
       " '',\n",
       " 'CCAACAGGCTATGAAGTC',\n",
       " 'AGTGTGCGAGGCGTTCTT']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oligo = list(complete_sequences)[0]\n",
    "print 'Example oligo ({} bp):'.format(len(oligo))\n",
    "oligo.pieces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0% of sequences have unusually high or low GC content\n"
     ]
    }
   ],
   "source": [
    "bad_gc_seqs = [seq for seq in complete_sequences if seq.gc_content >= 0.6 or seq.gc_content <= 0.4]\n",
    "print '{:.1f}% of sequences have unusually high or low GC content'.format(100*float(len(bad_gc_seqs))/len(complete_sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of seqs, barcodes: 6569\n"
     ]
    }
   ],
   "source": [
    "left_bcs = set(oligo._barcode_left for oligo in complete_sequences)\n",
    "right_bc_rcs = set(str(Seq(oligo._barcode_right).reverse_complement()) for oligo in complete_sequences)\n",
    "assert len(left_bcs) == len(right_bc_rcs)\n",
    "print 'Number of seqs, barcodes:', len(left_bcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw oligos range in length from 109 nt to 113 nt\n"
     ]
    }
   ],
   "source": [
    "raw_oligo_lens = set(map(len, complete_sequences))\n",
    "print 'Raw oligos range in length from {} nt to {} nt'.format(min(raw_oligo_lens), max(raw_oligo_lens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Primers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oligo lengths: set([132])\n"
     ]
    }
   ],
   "source": [
    "random.seed(rand_seeds[9])\n",
    "complete_sequences = design.update_buffers(\n",
    "    complete_sequences, \n",
    "    min_primer_len, \n",
    "    min_buffer_len,\n",
    "    target,\n",
    "    bad_substrs,\n",
    "    fudge_factor,\n",
    "    abs_cannonical_cut_sites,\n",
    "    pamtarg_coord_one_pos\n",
    ")\n",
    "\n",
    "print 'Oligo lengths:', set(map(len, complete_sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example oligo:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['AACCGCCGAATAACAGAGT',\n",
       " 'AAGAACACCGATAGCGCC',\n",
       " 'GCACTGA',\n",
       " 'TTTAGTGTTAAGTGAAATGCCATGTGG',\n",
       " 'TGCGATAGCGCTCGACTAGTACA',\n",
       " 'CC',\n",
       " 'CCAACAGGCTATGAAGTC',\n",
       " 'AGTGTGCGAGGCGTTCTT']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oligo = list(complete_sequences)[0]\n",
    "print 'Example oligo:'\n",
    "oligo.pieces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find usable primer prefixes (This step is RAM heavy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying 18\n",
      "Oligo lengths: set([132])\n",
      "Left/right buffers: GACTGCA / ACAGAGCACGATGTCTCTCGTAG\n",
      ".\n",
      "Trying 19\n",
      "Oligo lengths: set([134])\n",
      "Left/right buffers: TAGTCGCA / ACTAGCGACTAGACGTCGTGTCAT\n",
      ".\n",
      "Trying 20\n",
      "Oligo lengths: set([136])\n",
      "Left/right buffers: CGATACGTA / TACTCAGTCGCAGATATGCAGCAGT\n",
      ".*****\n",
      "Success!\n",
      "['TGGGCGGGTTTTCGGGTTTT', 'AAATAAAACGGGGGGGGAAA', 'CGGGGACACAAAAAGAAAAA', 'CTTTGTCGGGTTTGTTTGGG', 'TTGGGGGGGCTAAAAAGGGG']\n",
      "\n",
      "['TGGGCGGGTTTTCGGGTTTT', 'AAATAAAACGGGGGGGGAAA', 'CGGGGACACAAAAAGAAAAA', 'CTTTGTCGGGTTTGTTTGGG', 'TTGGGGGGGCTAAAAAGGGG']\n"
     ]
    }
   ],
   "source": [
    "for primer_len in range(min_primer_len, max_primer_len + 1):\n",
    "    print 'Trying', primer_len\n",
    "    random.seed(rand_seeds[3])\n",
    "    complete_sequences = design.update_buffers(\n",
    "        complete_sequences, \n",
    "        primer_len, \n",
    "        min_buffer_len,\n",
    "        target,\n",
    "        bad_substrs,\n",
    "        fudge_factor,\n",
    "        abs_cannonical_cut_sites,\n",
    "        pamtarg_coord_one_pos\n",
    "    )\n",
    "    print 'Oligo lengths:', set(map(len, complete_sequences))\n",
    "    oligo = list(complete_sequences)[0]\n",
    "    print 'Left/right buffers: {} / {}'.format(oligo._buffer_left, oligo._buffer_right)\n",
    "    \n",
    "    good_prefixes = design.find_good_prefixes(\n",
    "        complete_sequences, \n",
    "        primer_len, \n",
    "        bad_substrs,\n",
    "        cannonical_cut_sites,\n",
    "        fudge_factor,\n",
    "        nprocs\n",
    "    )\n",
    "    if len(good_prefixes) >= 2:\n",
    "        break\n",
    "    print \n",
    "\n",
    "assert len(good_prefixes) >= 2\n",
    "print\n",
    "print 'Success!'\n",
    "print good_prefixes\n",
    "print\n",
    "\n",
    "if primer_len == min_primer_len:\n",
    "    prev_good_prefixes = good_prefixes[:]\n",
    "    for fake_primer_len in range(primer_len-1, 0, -1):\n",
    "        print 'Trying buffers based on', fake_primer_len\n",
    "        random.seed(rand_seeds[3])\n",
    "        complete_sequences = design.update_buffers(\n",
    "            complete_sequences, \n",
    "            fake_primer_len, \n",
    "            min_buffer_len,\n",
    "            target,\n",
    "            bad_substrs,\n",
    "            fudge_factor,\n",
    "            abs_cannonical_cut_sites,\n",
    "            pamtarg_coord_one_pos\n",
    "        )\n",
    "        print 'Oligo lengths:', set(map(len, complete_sequences))\n",
    "        oligo = list(complete_sequences)[0]\n",
    "        print 'Left/right buffers: {} / {}'.format(oligo._buffer_left, oligo._buffer_right)\n",
    "\n",
    "        good_prefixes = design.find_good_prefixes(\n",
    "            complete_sequences, \n",
    "            primer_len, \n",
    "            bad_substrs,\n",
    "            cannonical_cut_sites,\n",
    "            fudge_factor,\n",
    "            nprocs\n",
    "        )\n",
    "        if len(good_prefixes) >= 2:\n",
    "            print\n",
    "            print good_prefixes\n",
    "            prev_good_prefixes = good_prefixes[:]\n",
    "        else:\n",
    "            break\n",
    "        print \n",
    "    print\n",
    "    print 'Failed, reverting to best previous:'\n",
    "    good_prefixes = prev_good_prefixes\n",
    "    fake_primer_len += 1\n",
    "print good_prefixes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replace primers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the above primers in your oligo analyzer of choice. If your experimental conditions require a longer primer, add bases as desired below. If you need shorter primers, do not change anything here. The full length of these primers is needed for the post-experiment analysis. Simply order primers with the inner bases removed as needed for your experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left / Right primers:\n",
      "TGGGCGGGTTTTCGGGTTTT\n",
      "AAATAAAACGGGGGGGGAAAG\n",
      "\n",
      "Hence, the oligos will have the form:\n",
      "\n",
      "TGGGCGGGTTTTCGGGTTTT    BC_left/Buf_left/Target/Buf_right/BC_right*    CTTTCCCCCCCCGTTTTATTT\n"
     ]
    }
   ],
   "source": [
    "left_primer = good_prefixes[0] + ''\n",
    "right_primer = good_prefixes[1] + 'G'\n",
    "cr_left = left_primer\n",
    "cr_right = fbseqtools.dna_rev_comp(right_primer)\n",
    "\n",
    "print 'Left / Right primers:'\n",
    "print left_primer\n",
    "print right_primer\n",
    "print\n",
    "print 'Hence, the oligos will have the form:'\n",
    "print\n",
    "print '{}    BC_left/Buf_left/Target/Buf_right/BC_right*    {}'.format(cr_left, cr_right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for oligo in complete_sequences:\n",
    "    oligo._cr_left = cr_left\n",
    "    oligo._cr_right = cr_right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oligo lengths: set([140])\n"
     ]
    }
   ],
   "source": [
    "print 'Oligo lengths:', set(map(len, complete_sequences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_ffolder = '/home/joneslab/Lab_Data/'\n",
    "seq_ffile ='target_{}_TnpB_Buffered_seqs.txt'.format(target_name)\n",
    "seq_fpath = seq_ffolder+seq_ffile\n",
    "exploded_seq_fpath = seq_ffolder+'exploded_' + seq_ffile\n",
    "\n",
    "with open(seq_fpath, 'w') as out:\n",
    "    out.write('\\n'.join([oligo.sequence for oligo in complete_sequences]))\n",
    "with open(exploded_seq_fpath, 'w') as out:\n",
    "    out.write('\\n'.join([oligo.tab_delimited_str() for oligo in complete_sequences]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_time = time.time() - notebook_start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run time: 884.993763208 seconds\n"
     ]
    }
   ],
   "source": [
    "print 'Run time: {} seconds'.format(total_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
